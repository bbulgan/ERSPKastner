{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambient Noise Signal Processing Detector\n",
    "__Contributors:__ Bilguun Bulgan, Coraline Sun, Caitlyn Liu, Isaac Castillo\n",
    "<br>__Instructors:__ Ryan Kastner, Perry Naughton, Tahiya Salam\n",
    "<br>__Description:__ This project is a part of the UC San Diego Early Scholars Research Program (ERSP). This detector was built particularly to detect the signals of the snapping shrimp of the La Jolla shore waters. The detector takes in a sound file, calcuates the frequencies with the Fourier Transformation, then returns \"a snap\" as a unit. The snap should have comprehensive attributes of a sound wave, including the direct arrival of the snap, and its corresponding reflected waves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from scipy import signal, arange\n",
    "from scipy.signal import hilbert, find_peaks_cwt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as matax\n",
    "import matplotlib.mlab as mlab\n",
    "import sys\n",
    "from math import exp\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#samplingFrequency: \n",
    "#read() returns sample rate of wave file as sampFreq (int) and data read from wav file (numpy array)\n",
    "sampFreq, sound = read('wav1.wav');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking 5 seconds of sample from 15s - 20sec in file \n",
    "#interval have 100 frames towards left and 400 frames towards right\n",
    "initTime = 0;    # the start time\n",
    "duration = int(len(sound)/sampFreq);     # duration of time period start at initTime\n",
    "\n",
    "###DO NOT CHANGE THE NEXT TWO VARIABLES!!! \n",
    "#IF CHANGED PLEASE RESET leftOffset TO 50 AND rightOffset to 200\n",
    "leftOffset = 50;  # how many frames we should expand the interval to the left (for the classfication algorithm)\n",
    "rightOffset = 200; # how many frames we should expand ther interval to the right (for the classificaiton algorithm)\n",
    "###DO NOT CHANGE THE LAST TWO VARIABLES!!!\n",
    "\n",
    "leftOffsetPeak = 100;\n",
    "rightOffsetPeak = 6000;\n",
    "windowSize = 0.01; # the size of the window we will ignore after capture the frame above threshold\n",
    "\n",
    "deadzone = 0 \n",
    "\n",
    "#start and end will hold the indeces in the sound sample array\n",
    "start = sampFreq * initTime;\n",
    "end = start + sampFreq * duration;\n",
    "\n",
    "#s1 holds the spliced soundsample array\n",
    "s1 = sound[start:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preparing timeArray for plotting. The plot will have x-axis in seconds (and not in indeces)\n",
    "timeArray = np.arange(0, end-start, 1)\n",
    "timeArray = timeArray / sampFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting up the amplitude threshold\n",
    "ampThreshold = np.std(s1) * 10\n",
    "\n",
    "#the boolean array about whether at each indexthe amplitude is above threshold or not\n",
    "aboveThres = s1 > ampThreshold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This displayes the amplitude graph (with the points of interested noted in dots) and the spectrogram\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "#fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "ax1 = fig.add_axes( [0.12, 0.55, 0.75, 0.4] )\n",
    "ax2 = fig.add_axes( [0.12, 0.1, 0.75, 0.4] )\n",
    "ax3 = fig.add_axes( [0.88, 0.1, 0.02, 0.4] )\n",
    "    \n",
    "#--- Figure 1. ---#\n",
    "ax1.plot(timeArray, s1)\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.set_xlim(0, duration)\n",
    "ax1.margins(x=0)\n",
    "\n",
    "#--- Figure 2. ---#\n",
    "f, t, Sxx = signal.spectrogram(s1, sampFreq, nperseg=256)\n",
    "Sxx[Sxx==0] = exp(-6)\n",
    "im = ax2.pcolormesh(t, f/1000, np.log(Sxx), cmap='jet' )\n",
    "\n",
    "#puts a mark at every point above the threshold\n",
    "ax1.scatter(timeArray[aboveThres],s1[aboveThres])\n",
    "\n",
    "ax2.set_ylabel('Frequency [kHz]')\n",
    "ax2.set_ylim(0,20)\n",
    "ax2.set_xlim(0, duration);\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.margins(x=0)\n",
    "im.set_clim(-10, 0)\n",
    "\n",
    "mappable = im\n",
    "cb = plt.colorbar(mappable = mappable, cax = ax3)\n",
    "cb.set_label('db/Hz')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pick out the time when the amplitude is above threshold\n",
    "timeArray[aboveThres]\n",
    "snaps = [];\n",
    "snapIndex = [];\n",
    "\n",
    "# current = the first time frame has amplitude above threshold\n",
    "# snaps = the time where each loud signal above threshold\n",
    "# snapIndex = the time frame indices of each loud signal above threshold\n",
    "current = timeArray[aboveThres][0] \n",
    "snaps.append(current)\n",
    "snapIndex.append(current * sampFreq)\n",
    "\n",
    "# set a 0.01sec time window that slides across the current array\n",
    "# so that we only collect one time data for each loud signal\n",
    "for time in timeArray[aboveThres]: \n",
    "    \n",
    "    if (time > current + windowSize ):\n",
    "        snapIndex.append(time * sampFreq)\n",
    "        snaps.append(time)\n",
    "        current = time\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFrequencies(signal):\n",
    "    length = len(signal) # length of the signal\n",
    "    #k = arange(length)\n",
    "    #T = length/sampFreq\n",
    "    #frq = k/T # two sides frequency range\n",
    "    #frq = frq[range(np.int(length/2))] # one side frequency range\n",
    "\n",
    "    frequencies = np.fft.fft(signal)/length # fft computing and normalization\n",
    "    frequencies = frequencies[range(np.int(length/2))]\n",
    "    \n",
    "    return abs(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotFrequencies(signal, ax):\n",
    "    length = len(signal) # length of the signal\n",
    "    k = arange(length)\n",
    "    T = length/sampFreq\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(np.int(length/2))] # one side frequency range\n",
    " \n",
    "    \n",
    "    ax.plot(frq, getFrequencies(signal),'r') # plotting the spectrum\n",
    "\n",
    "    ax.set_xlabel('Freq (Hz)')\n",
    "    ax.set_ylabel('|Y(freq)|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAmplitude(signal, time, ax):\n",
    "    \n",
    "    ax.plot(time, signal)\n",
    "    ax.set_xlabel('sample frames')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_xlim(front, back)\n",
    "    ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotEnvelope(signal, time, ax):\n",
    "    analytic_signal = hilbert(signal)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "   \n",
    "    instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    instantaneous_frequency = (np.diff(instantaneous_phase) / (2.0*np.pi) * sampFreq)\n",
    "\n",
    "    ax.plot(time, signal, label='signal')\n",
    "    ax.plot(time, amplitude_envelope, label='envelope')\n",
    "    ax.set_xlabel(\"time in seconds\")\n",
    "    ax.legend()\n",
    "    \n",
    "    return markPeaks(amplitude_envelope, time, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markPeaks(enveloped_signal, time, ax):\n",
    "    #peak_indexes contain the indeces of all the peaks found in the enveloped signal snippet \n",
    "    peak_indexes = find_peaks_cwt(enveloped_signal, arange(1, 20), noise_perc = 50);\n",
    "    \n",
    "    #tuple_array will contain a list of tuples in the form of \n",
    "    #(<index of the peak>, <amplitude value of the enveloped signal peak>)\n",
    "    tuple_array=[]\n",
    "    \n",
    "    \n",
    "    #print(\"x\")\n",
    "    #print(peak_indexes)\n",
    "    #print(\"y\") \n",
    "    #print(enveloped_signal[peak_indexes])\n",
    " \n",
    "    #populates the tuple_array\n",
    "    for i in peak_indexes:\n",
    "        data = (time[i],enveloped_signal[i])\n",
    "        tuple_array.append(data)\n",
    "    \n",
    "    #sorts the tuple_array by the 2nd element (which is the amplitude)\n",
    "    #so the leftmost element would be the peak with the highest\n",
    "    #amplitude value\n",
    "    tuple_array.sort(key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    #selected would contain the highest amplitude peak (at most 3, at least 2)\n",
    "    selected = []\n",
    "    count = 0\n",
    "    index = tuple_array[0][0]\n",
    "    selected.append(tuple_array[0])\n",
    "    for tuple_element in tuple_array:\n",
    "        if (tuple_element[0] > index + deadzone/sampFreq):\n",
    "            selected.append(tuple_element)\n",
    "            index = tuple_element[0]\n",
    "            count = count + 1\n",
    "        if (count == 2):\n",
    "            break;\n",
    "\n",
    "    index_list = [x[0] for x in selected]\n",
    "\n",
    "    amplitude_list = [x[1] for x in selected]\n",
    "    ax.scatter(index_list, amplitude_list, c ='r')\n",
    "    #print(time[0], time[len(time)-1])\n",
    "    #print(index_list)\n",
    "    ax.set_xlim(time[0], time[len(time)-1])\n",
    "\n",
    "    \n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def filterNLargestPeaks(n, peak_indexes, enveloped_signal):\n",
    "    highestPeaks = enveloped_signal[peak_indexes]\n",
    "    return peak_indexes[np.argsort(highestPeaks)[-n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRatio(signal):\n",
    "    frequencies = getFrequencies(signal)\n",
    "    ratio = sum(frequencies[34:68] * 100/sum(frequencies))\n",
    "    return ratio;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(signal):\n",
    "    #print(len(signal))\n",
    "    \n",
    "    ratio = getRatio(signal)\n",
    "    #print(ratio)\n",
    "    if (ratio > 70):\n",
    "        return \"Ping\"\n",
    "    \n",
    "    elif (ratio < 50):\n",
    "        return \"Snap\"\n",
    "    else:\n",
    "        return \"Undefined\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make a histogram\n",
    "sound_filtered = []\n",
    "for i in s1:\n",
    "    sound_filtered.append(abs(i))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#histogram code, now commented out\n",
    "num_bins = 10\n",
    "n, bins, patches = plt.hist(sound_filtered, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeInterval = []  # the time array for each sound clip\n",
    "signalInterval = []\n",
    "freq = []\n",
    "signal_id1 = []\n",
    "signal_id2 = []\n",
    "\n",
    "signal_timediff1 = []\n",
    "signal_timediff2 = []\n",
    "signal_count = 0\n",
    "\n",
    "for i in range(0, len(snapIndex)):\n",
    "#for i in range(0, 50):\n",
    "    front= int(snapIndex[i]-leftOffset)\n",
    "    back=  int(snapIndex[i]+rightOffset)\n",
    "    \n",
    "    frontPeak = int(snapIndex[i]-leftOffsetPeak)\n",
    "    backPeak = int(snapIndex[i]+rightOffsetPeak)\n",
    "    \n",
    "    time = timeArray[frontPeak:backPeak];\n",
    "    \n",
    "    signalForClassification = s1[front:back]\n",
    "    classification = classify(signalForClassification)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "    \n",
    "    #--- Figure 1. amplitude - time ---#\n",
    "    #plotAmplitude(signal, time, axes[0])\n",
    "    \n",
    "    signalForPeaks = s1[frontPeak:backPeak]\n",
    "    \n",
    "    signal_pairs = plotEnvelope(signalForPeaks, time, axes[0])\n",
    "\n",
    "    \n",
    "    #--- Figure 2. Y(freq) - freq ---#\n",
    "    plotFrequencies(signalForPeaks, axes[1])\n",
    "    \n",
    "    #--- Scatter Plot ---#\n",
    "    if (classification == \"Snap\"):\n",
    "        for i in range(1, len(signal_pairs)):\n",
    "            if( i == 1 ):\n",
    "                signal_id1.append(signal_count)\n",
    "                signal_timediff1.append(signal_pairs[i][0]-signal_pairs[0][0])\n",
    "            else:\n",
    "                signal_id2.append(signal_count)\n",
    "                signal_timediff2.append(signal_pairs[i][0]-signal_pairs[0][0])\n",
    "        signal_count = signal_count + 1\n",
    "\n",
    "    fig.suptitle(classification)\n",
    "    timeTitle = '%f-%f'%(frontPeak/sampFreq, backPeak/sampFreq)\n",
    "    fig.text(0,0,timeTitle)\n",
    "    \n",
    "    fname = \"\"\n",
    "    \n",
    "    if (classification == \"Snap\"):\n",
    "        fname ='../Plots/Snaps/%f-%f.png'% (frontPeak/sampFreq, backPeak/sampFreq)\n",
    "    elif (classification == \"Ping\"):\n",
    "        fname ='../Plots/Pings/%f-%f.png'% (frontPeak/sampFreq, backPeak/sampFreq)\n",
    "    else:\n",
    "        fname ='../Plots/undefined/%f-%f.png'% (frontPeak/sampFreq, backPeak/sampFreq)\n",
    "        \n",
    "    \n",
    "    #plt.show()\n",
    "     \n",
    "    #save image\n",
    "    fig.savefig(fname)\n",
    "    \n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the scatter plot\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "plt.scatter(signal_id1, signal_timediff1, c ='b')\n",
    "plt.scatter(signal_id2, signal_timediff2, c ='r')\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('arrival time diff in sample frames')\n",
    "plt.ylabel('first/second reflected wave')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
